question,answer
"A pair of values in an array are called consecutive if they are different and, after sorting, they appear in adjacent positions in the array.  

Given an array of natural numbers of size \( n \), propose an algorithm (with the best worst-case complexity) that checks whether there exists a pair of consecutive values whose total occurrences together are at least \( \left\lceil \frac{n}{2} \right\rceil \) 
(that is, the number of times a certain value appears plus the number of times its consecutive value appears is at least \( \left\lceil \frac{n}{2} \right\rceil \).","It is possible to solve in \( O(n) \) worst case in several ways based on order statistics.  
For example, a solution based on the following principles (without detailing technical specifics):  

- Finding the median â€“ \( O(n) \) (denoted as \( M \))  
- Finding the smallest element greater than the median (\( H \)) (if it exists) â€“ \( O(n) \)  
- Finding the largest element smaller than the median (\( L \)) (if it exists) â€“ \( O(n) \)  
- Counting occurrences of \( M \), \( L \), and \( H \) â€“ \( O(n) \)  

If the total occurrences of \( M \) and \( H \), or of \( M \) and \( L \), satisfy the condition, the answer is positive. Otherwise, it is negative.  "
"Given an array \( A \) containing \( n \) integers.  
Given a number \( x \) that appears in \( A \), we define the multiplicity of \( x \) in array \( A \) as the number of times \( x \) appears in \( A \).  
We want to create a sorted array \( B \) of size \( n \), which will contain the multiplicity of each number appearing in \( A \).  

Propose an algorithm that solves the problem with the best expected time complexity.  ","**Algorithm Description:**  

Insert the elements of the set into a hash table of size \( n \).  
Duplicate values will be tracked using a counter (i.e., during insertion, we traverse the list in the corresponding bucket, and only if the value is not found, we add a new element to the list with an initialized counter set to one).  
After inserting all elements, we traverse the table and extract all multiplicities.  
Since all values are integers in the range \( 1 \) to \( n \), they can be sorted using CountSort.  

**Time Complexity Proof:**  

- Insertion into the hash table â€“ total expected (average) \( O(n) \)  
- Extracting multiplicities from the table â€“ \( O(n) \)  
- CountSort â€“ \( O(n) \)  

**Total expected complexity: \( O(n) \)**  "
"Given two arrays \( A \) and \( B \), each of size \( n \), we want to create a third array \( C \) of size \( n \), with the following property:  
The value stored in \( C[i] \) is the number of elements in \( A \) that are smaller than \( B[i] \).  

Describe an algorithm with the best worst-case time complexity to solve this problem.","**Algorithm Description:**  

Sort \( A \) using HeapSort.  
For each element in \( B \), find how many elements are smaller than it using binary search in \( O(\log n) \).  

It is very important: If there are elements in \( A \) that appear more than once, a regular binary search will not work. Therefore, for each sampled value, if the sampled value equals the value we are searching for, the algorithm will not stop. Instead, it will recursively search the left half (which contains the smaller elements).  

**Time Complexity Proof:**  

- Sorting: \( O(n \log n) \)  
- \( n \) binary searches: \( O(n \log n) \)  

**Total: \( O(n \log n) \)**  "
"Given \( n \) distinct and sorted keys, describe an efficient data structure that maintains these keys (assume the structure is already built, so the cost of building it is not important) and supports the operation \( \text{find\_delete(key)} \), which receives a key and returns false if the key is not in the structure. If the key is in the structure, the operation returns true and removes it from the structure.  

Required cost: \( O(\log n) \) for the \( \text{find\_delete(key)} \) operation.","**Data Structure Description:**  
A balanced search tree.  

**Time Complexity of the Operation â€“ Explanation:**  
Finding an element in the tree, as well as deleting it, both take \( O(\log n) \) time."
"Describe an algorithm that solves the following problem:  
Given a set \( S \) of \( n \) numbers, the algorithm builds a data structure in \( O(n) \) worst-case time that supports only the \( \text{find} \) operation, such that:  
The worst-case time for \( \text{find} \) is \( O(n) \), but for at least \( \frac{n}{\log n} \) of the elements, the running time of \( \text{find} \) is \( O(\log n) \).  
Note that the structure is not dynamic, meaning it does not need to support insert or delete operations.","**Algorithm Description and Correctness Proof:**  

Take \( \frac{n}{\log n} \) elements and insert them into a balanced search tree (e.g., 2-3 tree) or a sorted array. The total cost is \( O(n) \). The remaining elements are inserted into a list.

During the execution of \( \text{find} \), first search in the tree, and then in the list. The search cost for each element in the tree is \( O(\log n) \), while for the remaining elements, it is \( O(n) \)."
"We want the most efficient algorithm possible for the following problem:

**Input:** \( n \) segments on the line (i.e., \( n \) pairs of start and end points).

**Question:** Is there a set of three segments in the input that have at least one common intersection point?","**Algorithm Description and Time Complexity Analysis:**

Build an array that contains all the endpoints of the segments. Mark each point as either a start or an end point. First, sort the array so that the points are arranged from left to right. In case of a ""tie,"" i.e., if the points are equal, place the start points before the end points in the array. Next, scan the array, and at each step, keep track of the number of start points encountered minus the number of end points encountered, simply by subtracting 1 from a counter when passing an end point, and adding 1 when passing a start point. It is easy to see that the counter corresponds exactly to the number of segments that the current point lies within. It is also clear that if there are three segments that intersect at a common point, there is a point where this condition holds and is a segment endpoint. Therefore, we need to return 'yes' if and only if the counter reaches a value of at least 3 at any point during the scan. The sorting step takes \( O(n \log n) \), and the scan is linear, so the total time complexity is \( O(n \log n) \).

**Common Mistakes:**

1. Some solutions sorted the segments by start point and then checked if there were three adjacent segments in the array that intersected at the same point. This is incorrect because it is possible for three segments to intersect at the same point even if there is no triple with the start points aligned. For example, consider the following scenario:

% You can add an example here if necessary.

2. Some solutions checked only if there were three adjacent segments such that the first intersects with the second and the second intersects with the third, but did not check that all three intersect at the same point."
"**Data Structure Description:**

Describe a data structure that maintains a set of points in the plane, where each point \( p_i \) is represented as a pair of numbers \( (x_i, y_i) \). The data structure should support the following operations:

- \( \text{insert}(x, y) \), \( \text{delete}(x, y) \), \( \text{find}(x, y) \) in the worst-case time complexity of \( O(\log n) \).
- \( \text{CountPointsAtDistance}(d_1, d_2) \), which performs the following operation: Given two numbers \( d_1 \) and \( d_2 \), the function returns the number of points in the structure whose distance from the origin is greater than \( d_1 \) and smaller than \( d_2 \). Recall that the distance of a point \( (x, y) \) from the origin is \( \sqrt{x^2 + y^2} \).

The \( \text{CountPointsAtDistance}(d_1, d_2) \) operation should be executed with the lowest possible time complexity.","**Balanced Search Tree (2-3 or AVL, for example):**

The key in the tree is the distance \( d \). Under each leaf, there is a 2-3 tree that holds the corresponding keys \( (x, y) \) in lexicographical order.  
The main tree is structured as an ORDER STAT tree, where each node stores the number of keys in its subtree.

**Implementation of the CountPointsAtDistance Operation and its Time Complexity:**

1. Find the point that is the farthest from the origin such that its distance is less than \( d_2 \).
2. Compute its order statistic: \( a \).
3. Find the point that is the closest to the origin such that its distance is greater than \( d_1 \).
4. Compute its order statistic: \( b \).
5. Return \( a - b + 1 \).

Each of the above steps is performed in \( O(\log n) \) worst-case time. Therefore, the total time complexity of the operation is \( O(\log n) \)."
"**Algorithm Description for Solving the Problem:**

**Input:** A set \( \{a_1, a_2, \dots, a_n\} = A \) of \( n \) numbers.

**Goal:** The algorithm should construct a data structure \( DS \) in the best average-case time, with the following property: Given a collection \( S \) of \( m \) numbers, whose elements are taken from \( A \), we can use \( DS \) to sort the elements of \( S \) in \( O(\max(m, n)) \) worst-case time.  

Note that \( S \) may contain any element of \( A \) multiple times, so it is possible that \( m > n \).","**Description of the Data Structure \( DS \):**

A perfect hash of the elements according to their value. For each element, we also store its rank (statistical order).

**Description of Building the Structure:**

1. Sort the array in \( O(n \log n) \) time to find the rank of each element.
2. Insert the elements into the perfect hash table in \( O(n) \) on average.

**How to Sort Using the Data Structure:**

1. Find the statistical order (rank) of each element in \( S \).
2. Sort \( S \) according to the ranks using CountSort."
"**In this question, we will discuss the Quicksort algorithm. Throughout the question, we assume the input is an array of length \( n \), and we are interested only in arrays where all elements are distinct. As is known, each sorting algorithm has an associated binary tree that represents the comparisons the algorithm performs for all possible inputs.**

We are interested in the Quicksort algorithm where the pivot element is always chosen to be the first element of the segment of the array the algorithm is working on (rather than being chosen randomly), and we will focus on the comparison tree corresponding to this algorithm.

**(A) What is the smallest depth of a leaf in this comparison tree as a function of \( n \)?**","**Answer and Explanation:** \( O(n \log n) \), for the same reason that regular Quicksort requires \( O(n \log n) \) comparisons. In the best-case scenario, the array is divided into two parts of size \( O(n) \), and there will still be \( O(\log n) \) steps, with the number of comparisons at each step being \( O(n) \)."
"Describe an implementation of the DeleteMin operation in a heap (Heap) as we discussed in class, which performs \( O(\log(n)^{0.5}) \) comparisons in the worst-case scenario, or prove that such an implementation is impossible.","Such an implementation is impossible. Otherwise, it would be possible to sort \( n \) elements in the comparison model in \( o(n \log n) \) time, which contradicts what we proved in class. This can be done by building a heap in linear time (as we learned) and then calling DeleteMin \( n \) times, printing the element obtained each time."
"Given \( n \) segments on a line (each segment is defined by its start and end points). For simplicity, assume that all \( 2n \) points are distinct. A segment is called ""central"" if there are at least \( n/4 \) segments that start before it (i.e., their starting point is to the left of its starting point) and there are at least \( n/4 \) segments that end after it (i.e., their ending point is to the right of its ending point). Propose an algorithm that returns the number of central segments, with the best possible worst-case running time.","Algorithm: Running time \( O(n) \).

Find the \( n/4 \)-th smallest element among the start points, call it \( a \).
Find the \( n/4 \)-th smallest element among the end points, call it \( b \).
Scan through the segments one by one and count how many start after \( a \) and end before \( b \).

Time complexity analysis: Finding the \( i \)-th smallest element takes \( O(n) \) using the Select algorithm. The scan takes \( O(n) \) because each check takes two comparisons, i.e., \( O(1) \)."
"Given \( n \) segments on a line (each segment is defined by its start and end points). For simplicity, assume that all \( 2n \) points are distinct. A segment is called ""central"" if there are at least \( n/4 \) segments that start before it (i.e., their starting point is to the left of its starting point) and there are at least \( n/4 \) segments that end after it (i.e., their ending point is to the right of its ending point). Propose a dynamic data structure that supports the operations Insert and Delete of segments on the line in \( O(\log n) \) worst-case time, and also supports the operation IsCentric(p), which takes a pointer to a segment in the structure and answers whether the segment is central, in \( O(1) \) worst-case time.","Description of the structure:
A balanced tree containing all the start points, which also serves to find the order-statistic as learned in class, by maintaining the number of descendants of each node.
Another such tree containing the end points.
In the tree of start points, there will be a pointer \( p_1 \) to the node representing the \( n/4 \)-th smallest element.
In the tree of end points, there will be a pointer \( p_2 \) to the node representing the \( 3n/4 \)-th smallest element.

Implementation of the Insert operation and time complexity analysis:
We insert the start point of the segment into the first tree and update the number of descendants in each node as learned in class.
Additionally, we find the \( n/4 \)-th smallest element in the tree and update the pointer \( p_1 \).
Similarly, we do this for the end point and the second tree, with pointer \( p_2 \).
The insertion into an order-statistic tree takes \( O(\log n) \) as learned in class, and the same time is taken to find the corresponding element.
Total: \( 2 \times 2 \times O(\log n) = O(\log n) \) time complexity.

Implementation of the Delete operation and time complexity analysis:
Similar to the Insert operation, we delete the start point value from the first tree and update \( p_1 \). Similarly for the second tree.
 
Implementation of the IsCentric operation and time complexity analysis:
We check if the start point of the given segment is greater than \( p_1 \) and smaller than \( p_2 \). Time: \( O(1) \), as we perform only 2 comparisons."
"Given a min-heap, with no duplicate keys.
Each node \( x \) has an additional field \( s \), which is initialized to \( \text{nil} \). We want the field \( s \) of each node \( x \) to contain a pointer to the successor of \( x \). Assume that access to the heap elements is available (i.e., the heap is not a black box). The heap structure itself should not be changed. Propose an algorithm that achieves this, with the best possible overall worst-case time complexity, given that the keys are integers in the range from 1 to \( 2n \).","Description of the algorithm:
I. We will scan the heap (for example, using DLR traversal) and copy the keys to an auxiliary array. For each key, we will remember its pointer to its original position in the heap.
II. We will sort the array using a linear-time sorting algorithm, such as CountSort (or BinSort).
III. We will scan the array from left to right, and for each element, we will access (using the pointer) the corresponding node in the heap and update the field \( s \) to contain the pointer to the next element in the array."
"In B-trees with a minimum degree \( d \) (where each internal node has between \( d \) and \( 2d \) children), the amount of information stored in the leaves is smaller because there is no need to store child pointers. Assume that a disk block is large enough to hold a node at its maximum size and that each node is stored in a separate disk block.

To take advantage of the free space in the disk block containing a leaf, we modify the definition of the tree and set that each leaf will contain between \( 2d-1 \) and \( 4d-1 \) elements, instead of between \( d-1 \) and \( 2d-1 \). It is given that the size of an element is equivalent to the size of a pointer, so such an enlarged leaf still fits in a block. As long as the tree has no more than \( 4d \) elements, the tree consists of a single enlarged leaf.

This is called a B-tree with enlarged leaves. Briefly describe a top-down insertion algorithm (the algorithm does not modify the tree after the element is inserted into the appropriate leaf, only during the search) for a B-tree with enlarged leaves as described above.","We search for the location of the new element in the tree starting from the root. Each time we descend along the path to a full node (a node containing \( 2d \) children), we split it, so that no chain of splits occurs when we reach a leaf. When we reach a leaf, we insert the element as usual. At this point, at most one split may occur."
"We insert a set of elements \( X_1 \) of size \( n_1 \) into a hashing table of size \( m \) using the chaining method with the hashing function \( h \). All the linked lists formed in this table had a length of at most \( k_1 \). We then insert a second set of elements \( X_2 \) of size \( n_2 \) into another hashing table of size \( m \), also using the chaining method with the same hashing function \( h \). The linked lists formed in this table had a length of at most \( k_2 \). Finally, we insert all the elements of \( X_1 \) and \( X_2 \), in some order, into a third hashing table of size \( m \), again using the chaining method and the same hashing function \( h \). Provide a non-asymptotic bound, as tight as possible, on the number of keys that will be examined during a search operation (whether successful or unsuccessful) in the third hashing table.","The number of keys that will be examined during a search operation is exactly the length of the list. 
In one list, there will be at most \( k_1 + k_2 \) elements, so this is the maximum number of keys that will be examined during any search operation."
"Given a directed graph defined by a set of \( n \) nodes and \( m \) edges, where each edge is an ordered pair of nodes. The outgoing edges from each node are stored in a singly linked list.

Each node \( v \) is represented by an object that supports the following operations:
- \( \text{edges}(v) \): Returns the list of edges outgoing from node \( v \).
We assume the graph has \( n \) nodes, each identified by an integer between 1 and \( n \). The operation \( \text{id}(v) \) returns the integer identifier of node \( v \).
The entire graph is represented by an array of size \( n \), where the element \( \text{id}(v) \) points to the object representing node \( v \).

On the edge list \( L \) (outgoing from a specific node), the following operations can be performed:
- \( \text{first}(L) \): Returns the first edge in the list.
- \( \text{delete-first}(L) \): Removes the first edge from the list.
- \( \text{insert-first}(L, e) \): Inserts an edge object \( e \) at the beginning of the edge list \( L \).
- \( \text{length}(L) \): Returns the length of the list \( L \).

Each edge \( e = (v, w) \) is represented by an object that supports the following operations:
- \( \text{next}(e) \): Returns the next edge in the outgoing edge list from \( v \).
- \( \text{delete-after}(e) \): Removes the edge after \( e \) in the outgoing edge list from \( v \).
- \( \text{source}(e) \): Returns the source node \( v \) from which \( e \) originates.
- \( \text{target}(e) \): Returns the target node \( w \) to which \( e \) points.

These are the only operations that can be performed on the objects representing the graph.

For algorithm analysis, let \( d(v) \) denote the number of outgoing edges from node \( v \).

\textbf{(A)} Given two nodes \( v \) and \( w \), describe the most efficient algorithm you can to check if there is an edge from \( v \) to \( w \). What is the running time of the algorithm?","We iterate through the list of edges outgoing from \( v \) and check if there is an edge \( (v, w) \). The running time is \( O(d(v)) \)."
"Describe a data structure whose elements are pairs of keys \( (a, b) \) that supports the following operations:

\begin{itemize}
    \item \texttt{insert(a, b)} â€“ Adds the key pair \( (a, b) \) to the data structure. It is assumed that the pair does not already exist in the structure. This operation should be performed in expected time \( O(1) \).
    \item \texttt{SearchAll(a)} â€“ Returns a list of all key pairs where \( a \) is the left key. This operation should be performed in expected time \( O(1) \).
\end{itemize}","We implement the data structure using a hash table on the left key \( a \), where each cell in the hash table holds a list of all key pairs for which \( a \) is the left key. The \texttt{insert} operation will insert the element at the beginning of the list, and \texttt{SearchAll} will return the entire list."
"Given \( n \) pairs of keys \( (a_1, b_1), (a_2, b_2), \dots, (a_n, b_n) \), where each key \( a_i \) and each key \( b_j \) (for \( 1 \leq i,j \leq n \)) are integers in the range \([1, 10n]\), describe a data structure that can be built in Worst-case time \( O(n) \) (given \( n \) key pairs) and supports the following operation in Worst-case time \( O(1) \):

\texttt{SearchAll(a)} â€“ returns a list of all key pairs for which \( a \) is the left key.","We initialize a table with \( 10n \) cells, such that the \( i \)-th cell holds a list of all key pairs for which \( i \) is the left key."
"Describe a data structure whose elements are pairs of keys \( (a, b) \), where each left key in the pair is an integer in the range \([1, 10n]\). It can be assumed that all the key pairs are distinct. The data structure should support the following operations (where \( n \) is the number of key pairs currently in the data structure):

\begin{itemize}
    \item \texttt{Insert(a, b)} â€“ Adds the key pair \( (a, b) \) to the data structure. The operation should be performed in amortized time \( O(1) \).
    \item \texttt{IncreaseKey((a, b), x)} â€“ This command receives a pointer to the key pair \( (a, b) \) that is in the data structure and a positive number \( x \), and increases the right key by \( x \). The operation should be performed in amortized time \( O(1) \).
    \item \texttt{Delete((a, b))} â€“ This command receives a pointer to the key pair \( (a, b) \) that is in the data structure and deletes it. The operation should be performed in amortized time \( O(\log n) \).
\end{itemize}","We implement using an array where each cell points to a maximum heap. In each operation, we access the \( a \)-th cell in the array and perform the corresponding operation on the heap with key \( b \)."
"Describe a data structure whose elements are pairs of keys \( (a, b) \) that supports the following operations (where \( n \) is the number of key pairs currently in the data structure, and it can be assumed that all the key pairs are distinct):

\begin{itemize}
    \item \texttt{Insert(a, b)} â€“ Adds the key pair \( (a, b) \) to the data structure. The operation should be performed in \( O(\log n) \) time.
    \item \texttt{Delete(a, b)} â€“ Deletes the key pair \( (a, b) \). The operation should be performed in \( O(\log n) \) time.
    \item \texttt{Search(a, b)} â€“ Returns the key pair \( (a, b) \) if it exists, otherwise returns null. The operation should be performed in \( O(\log n) \) time.
    \item \texttt{successor(a, b)} â€“ Returns \( (a, b^*) \) where \( b^* \) is defined as follows: let \( b_1, b_2, b_3, \dots, b_m \) be all the keys such that the pair \( (a, b_i) \) exists in the data structure (for \( 1 \leq i \leq m \)) and is sorted in ascending order. Then, \( b^* \) is the key to the right of \( b \) in the sorted list. If there is no key to the right of \( b \) in the sorted list, return null. The operation should be performed in \( O(\log n) \) time.
\end{itemize}","We implement using a Red-Black tree where each node points to a Red-Black tree. In each operation, we search on the main tree using \( a \) and on the secondary tree (pointed to by a node in the main tree) using \( b \)."
"Describe a data structure that supports the following operations (where \( n \) is the number of keys currently in the data structure, and it can be assumed that all the keys are distinct):

\begin{itemize}
    \item \texttt{Insert(a)} â€“ Adds the key \( a \) to the data structure. The operation should be performed in \( O(\log n) \) time.
    \item \texttt{Delete(a)} â€“ Deletes the key \( a \). The operation should be performed in \( O(\log n) \) time.
    \item \texttt{Search(a)} â€“ Returns the key \( a \) if it exists, otherwise returns null. The operation should be performed in \( O(\log n) \) time.
    \item \texttt{Sum(a)} â€“ Returns the sum of all the keys smaller than \( a \). It can be assumed that \( a \) exists in the data structure. The operation should be performed in \( O(\log n) \) time.
\end{itemize}","We implement using a Red-Black tree where each node stores the sum of the keys in the subtree rooted at that node. The \texttt{Sum} operation will be performed by traversing from the root to \( a \) and summing the sum fields of all the left children of the nodes along the path, along with the sum field of \( a \)."
"Given an ordered set \( S \), we define the degree of an element in the set as its position in a sorted array of the elements (all elements have different values). Throughout the question, \( h \) represents the number of elements currently in the requested data structure.

\textbf{(A)} Describe a data structure that supports the following operations:
\begin{itemize}
  \item \texttt{Init()} â€“ initialize the structure in \( O(1) \) time.
  \item \texttt{Insert(x)} â€“ insert the element \( x \) into \( S \) in \( O(\log n) \) time.
  \item \texttt{Delete(x)} â€“ delete the element \( x \) from \( S \) in \( O(\log n) \) time.
  \item \texttt{Min()} â€“ return the element with the minimum degree (smallest value) in \( O(1) \) time.
  \item \texttt{Max()} â€“ return the element with the maximum degree (largest value) in \( O(1) \) time.
  \item \texttt{AVG()} â€“ return the element with the minimum degree whose value is greater than or equal to the average of the elements in the structure in \( O(1) \) time.
\end{itemize}","We will use a balanced binary tree with auxiliary fields that are updated with each \texttt{insert}/\texttt{delete} operation: pointers to the minimum and maximum elements (which are found by walking left or right from the root to a leaf), a pointer to the element with the minimum value greater than or equal to the average, the number of elements in the tree, and the sum of the elements in the tree. 

To maintain the pointer to the average element, during an insertion, we will update the number of elements and the sums, compute the average, and find the closest element greater than or equal to the average by searching for it. Similarly, the same process is applied for the \texttt{delete} operation.

For \texttt{Min}/\texttt{Max}/\texttt{AVG} calls, we return the element based on the corresponding pointer."
"Given an array of $n$ numbers. In all questions, we want to find an element that repeats a certain number of times in the array. If there is more than one such element, we should return one of them.
Propose an algorithm to find the repeating element in each of the following cases:

\textbf{a.} It is known that there is an element that repeats at least $L$ times. In this case, randomness can be used.",We will maintain a Hash table where the key is the number and the value is a counter. We will iterate through the input array and count the occurrences of each element. We will then iterate again and return an element whose counter value is at least $L$. The expected time complexity is $O(n)$.
"Given an array of $n$ numbers, describe an algorithm with a time complexity of $O(n)$ that checks whether there is an element that appears at least $n/8$ times in the array. Prove your answer.","We will perform select on the elements at positions $n/9$, $2n/9$, $3n/9$, $4n/9$, $5n/9$, $6n/9$, $7n/9$, and $8n/9$. Now, we will iterate over the array and check if any of the 8 candidates appears at least $n/8$ times."
"Given an array with $n$ numbers.

\textbf{B.} Describe a deterministic algorithm with time complexity $O(n \log n)$ that returns the number of distinct elements in the array. Prove your answer.","Sort the array using merge sort. Now, traverse the sorted array and every time we encounter an element that is different from the previous one, increment a counter by 1."
"Given a collection of sets $s_1, s_2, \dots, s_m$.

Describe a data structure that supports the following operations:

\begin{itemize}
    \item \texttt{MakeItem(i) $\gets$ A} â€“ Create the item $A$ that holds the number $i$.
    \item \texttt{Insert(j, A)} â€“ Insert the item $A$ into set $S_j$ (it is assumed that the set $S_j$ exists).
    \item \texttt{Delete(j, A)} â€“ Delete the item $A$ from set $S_j$ (it is assumed that the set $S_j$ exists).
    \item \texttt{FindMin(j)} â€“ Return the minimum item from set $S_j$ (it is assumed that the set $S_j$ exists).
    \item \texttt{CreateSet(j, Arr)} â€“ Build the set $j$ from an unsorted array of numbers.
    \item \texttt{FindMin()} â€“ Return the minimum item among all items in the sets $s_1, s_2, \dots, s_m$.
\end{itemize}

All operations, except for \texttt{CreateSet}, should run in $O(\log n)$ time, where $n$ is the total number of items in sets $s_1, s_2, \dots, s_m$. The \texttt{CreateSet} operation should run in linear time relative to the size of the input array.","We will maintain a minimum heap for each set and additionally a minimum heap that will store the minimum value of each of the sets. 

The operations \texttt{Delete(j, A)}, \texttt{CreateSet(j, arr)}, and \texttt{Insert(j, A)} will update the minimum heap of the set $s_j$. If the minimum element of a set is updated, the global minimum heap will also be updated. 

The operation \texttt{FindMin(j)} will return the minimum element from the corresponding heap of set $s_j$. 

The operation \texttt{FindMin()} will return the minimum element from the global heap of all sets."
"Given an array of $n$ integers between $0$ and $2^n$.
It is given that each number in the array is a multiple of the upper bound value of $2^N$, divided by $N^3$. Propose an algorithm to sort the array.","Divide each number by (the upper bound value of $2^N$, divided by $N^3$). Now, the elements of the array are in the range $[0, n^3]$ and can be sorted using $O(n)$ \texttt{radix sort}."
"A data structure is required that supports the following operations on elements containing two fields: \texttt{id} and \texttt{amount}. At any given time, the number of elements in the structure does not exceed $N$.

\begin{enumerate}
    \item \texttt{Add(i,x)}: Increases the value of the \texttt{amount} field of the element (the only one) with \texttt{id} = $i$, by $x$ if it exists. Otherwise, if no such element exists, it adds an element with \texttt{id} = $i$, \texttt{amount} = $x$ (no pointer is given to the element).
    \item \texttt{whoIsMax()}: Returns the \texttt{id} for which the \texttt{amount} field is maximal (if more than one exists, returns one of them).
    \item \texttt{Reduce(i,y)}: Decreases the \texttt{amount} of the element with \texttt{id} = $i$ by $y$ (no pointer is given to the element).
\end{enumerate}

Assume that all \texttt{id}s are in the range $[1, 3n]$.

Describe a deterministic data structure that supports operations 1 and 2 in $O(1)$ time in the worst case (there is no need to implement operation 3).","We will allocate an array of size $3n$. In each call to \texttt{Add}, we will update the corresponding cell in the array and check if it is the new maximum by comparing it with the current maximum. The \texttt{whoIsMax} function will return the maximum, which will always be stored in an auxiliary field."
"Is it possible to implement an AVL tree such that the worst-case time complexity of the insert operation is \( O(1) \) and the delete operation takes \( O(n) \), where \( n \) is the number of elements in the tree?","It is not possible. Consider a general set of numbers of size \( n \), insert them into the tree, and retrieve them sorted using an in-order walk in \( O(n) \)."
"Is it possible to implement any search tree such that the insert operation takes \( O(1) \) in the worst case and the delete operation takes \( O(n) \), where \( n \) is the number of elements in the tree?","It is not possible. Consider a general set of numbers of size \( n \), insert them into the tree, and retrieve them in sorted order using an in-order walk in \( O(n) \)."
"Is it possible to implement an AVL tree with an additional operation that returns the smallest element greater than or equal to the average of the elements in \( O(1) \) time, without affecting the runtime of other operations?","We will maintain an auxiliary pointer that will be updated during each insert and delete operation, pointing to the relevant element. This will require updating the average at each step and searching for the appropriate element, which will take \( O(\log n) \) time."
"We construct a hashing table of size \(m\) using the chaining method. The hash function is randomly selected from a universal family of hash functions. \(n\) distinct elements have already been inserted into the table. Now, we perform a search for an element \(x\) that is already in the table. Provide the best possible bound (not asymptotic) on the expected number of elements in the list where \(x\) is located.",1 + \frac{n-1}{m}
"We build a hashing table of size \( m \) using the open addressing method (i.e., all the elements are in the hashing table without using pointers). We use a randomly chosen hash function of the form \( h(k, i) \), where \( k \) is the key that we want to insert into the table, and \( i \) is the probe number. (This is the uniform probing method. The value returned by calling \( h(k, i) \) is a uniformly chosen integer between 2 and \( m-1 \), independent of the previous random selections). The table already contains \( n \) distinct elements. We now perform a search for an element that is not in the table. What is the expected number of table slots examined during the search? Provide as tight a non-asymptotic answer as possible.",\frac{1}{1 - \frac{n}{m}}
"We build a hashing table of size \( m \) using the linear probing method. The keys of the elements inserted into the table are taken from the set \( \{0, 1, \dots, 2m-1\} \). We use the following hash function:
\[
h(k) = \left\lfloor \frac{k}{2} \right\rfloor.
\]
We insert the elements \( 1, 2, \dots, m \) into the table in increasing order. How much time does it take to insert all the elements into the table using the standard insertion algorithm? Provide an asymptotic bound.",Quadratic time.
"Let \( U = \{0, 1, \dots, u\} \). Assume that each element of \( U \) can be represented by a single word. Given a subset \( D \subseteq U \) of size \( n \), describe the most efficient probabilistic algorithm that constructs a function \( h: U \to \{0, 1, \dots, 100n\} \) which is injective on \( D \) (i.e., for all \( x, y \in D \), we have \( h(x) \neq h(y) \)). The memory required to represent the function \( h \) should be \( O(n) \). Computing \( h(x) \), given \( x \in D \), should take \( O(1) \) time in the worst case.",perfect hash
"We define a zig-zag array, for which there exist some indices \( n \leq j \leq i \leq 1 \) such that all elements in the array between 1 and \( i \) are in increasing order, all elements between \( i \) and \( j \) are in decreasing order, and all elements between \( j \) and \( n \) are in increasing order. We call \( i \) the peak element and \( j \) the valley element. 

Provide upper and lower bounds for the problem: Input: Array. Output: Returns TRUE if the array is a zig-zag array.",Upper and lower bounds are \( O(n) \).
"Given \(n\) segments on the line (i.e., the input is \(n\) pairs \((x, y)\) of start and end points), a segment is called ""central"" if there are at least \(n/4\) segments starting before it (its start point is to the left of its start point) and at least \(n/4\) segments ending after it (its end point is to the right of its end point). Propose an algorithm that returns the number of central segments, with the best possible Worst Case running time, and analyze its running time.","One can run a select on \( n/4 \) in \( x \) and \( 3n/4 \) in \( y \), and based on that, identify the central segments. The running time is linear in the number of segments."
"Given a node \( v \) in a red-black tree. \( P_1 \) and \( P_2 \) are the lengths of the shortest path and longest path from \( v \) to a leaf, respectively. Provide a lower bound on the ratio between \( P_1 \) and \( P_2 \). Justify your answer.",\textit{Maximum twice the length because there is the same black length and no two consecutive reds}
"\textit{We insert into a binomial heap (initially empty) the sequence of numbers 1, 2, \ldots, n in ascending order. For two binomial trees in the heap created, with ranks i, j such that i < j, what is the relation between all the values in the tree of rank i and all the values in the tree of rank j? Explain.}","All the nodes in the tree with rank \( j \) were inserted before all the nodes in the tree with rank \( i \). Therefore, the nodes in the tree with rank \( j \) are smaller than all the nodes in the tree with rank \( i \)."
"\textbf{Reminder:} In perfect hash, we choose a random universal hash function to map a given space \( U \) of size \( n \) to an array of size \( n \). Let \( n_i \) be the number of elements mapped to cell \( i \). Then, a random universal hash function is used to map the elements mapped to cell \( i \) to another array of size \( n_i^2 \).

\textbf{Question:} 

Define: A nearly universal family of functions is a family of functions from space \( U \) to \(\{0, \ldots, m-1\}\) such that for any pair of keys \( k_1, k_2 \) in \( U \) the condition \( \Pr(h[k_1] = h[k_2]) \leq 1/m^{0.5} \) holds. Suppose we have a nearly universal family when \( |U| = n \). We take a random function from the family and use it to map the elements of \( U \) to an array of size \( m \). What is the best upper bound on the expected number of collisions if \( m = n^4 \)?","\text{Answer = 0.5. There are } \frac{n^2}{2} \text{ possible collisions and the probability for each is } \frac{1}{\sqrt{m}} = \frac{1}{n^2}, \text{ so by linearity of expectation we get 0.5.}"
"The deterministic ""select"" algorithm, which we studied in class, works as follows:
a. The array is divided into groups of size 5
b. Sort each group
c. Choose a pivot as the median of the medians (recursively)
d. Perform ""partition"" with the chosen pivot
e. Recursively apply the algorithm on the relevant part.

Assume that instead of groups of size 5, we take groups of size 3. 
In this question, we will deal with the running time of the new algorithm with groups of size 3.
What is the cost of step b? 
Cost:
Explanation:","\text{Cost: } O(N) \\
\text{Explanation: Sorting each triplet is fixed, and there are } N/3 \text{ triplets.}"
"\textit{We will implement an n-bit binary counter. The counter is initialized to the value 0...00. The Inc operation advances the counter, i.e., increases its value by 1 as follows. The operation searches sequentially for the rightmost 0, turns it into a 1, and turns all the 1s to its right into 0s. If the state of the counter is 1...11, then advancing it will change its state to 00...0. For example, if n=5 and the counter state is currently 00111, then after the Inc operation, the counter state will be 01000. After another Inc operation, the counter state will be 01001. The cost of an operation is defined as the number of bits whose value is changed by the operation. For example, the cost of advancing the counter in the example from 00111 to 01000 is 4, since 4 bits changed their value. The answer should be exact, not asymptotic in terms of O(). What is the cost of the Inc operation in the worst case?","The answer is: \( N \) because it is the number of bits in the numerator, and they can all change in one operation."
"\textbf{We will implement a binary counter with $n$ bits. The counter is initialized to the value $0 \ldots 00$. The Inc operation advances the counter, meaning it increases its value by 1 as follows. The operation sequentially searches for the rightmost 0, turns it into a 1, and converts all 1's to its right into 0's. If the counter's state is $1 \ldots 11$, then advancing it will change its state to $00 \ldots 0$. For example, if $n=5$ and the counter state is currently $00111$, then after the Inc operation the counter state will be $01000$. After another Inc operation, the counter state will be $01001$. The cost of an operation is defined as the number of bits whose value is changed by the operation. For instance, the cost of advancing the counter in the example from $00111$ to $01000$ is 4, as 4 bits changed their value. The answers to the following sections need to be precise, not asymptotic in terms of $O(.)$. We will define a Double-Inc operation that calls for two consecutive Inc operations. What is the cost of the Double-Inc operation in the worst case? Explain.}","\textbf{Answer:} n+1 \\
Any two operations necessarily include an operation where only the first bit changes, and therefore in the worst case, it's n+1."
"\begin{enumerate}
    \item Given an array containing n elements. The number of distinct elements is k (ð‘› â‰¤ ð‘˜).
    \item Sort the following asymptotic orders without explanation (ð‘› â‰¤ ð‘˜):
    \begin{itemize}
        \item n \log n,
        \item n,
        \item n \log k,
        \item n + k \log k,
        \item n^2
    \end{itemize}
\end{enumerate}","n^2, n\log{n}, n\log{k}, n+k\log{k}, n"
"\text{Given an array containing } n \text{ elements. The number of distinct elements is } k \, (k \leq n). \\
\text{d. Assume the elements are integers between } 1 \text{ and } n^4. \text{ Propose a deterministic algorithm to sort the array.}",We will use the count sort algorithm as taught in class. \(O(n)\).
"\textit{Given a series of n elements, what is the time complexity for finding the k smallest elements in the series (for k < n).}","\textbf{Time complexity:} \(O(n)\) \\
\textbf{Brief explanation:} Using a selection algorithm we saw in class and then partition."
"\begin{quote}
In the following section, the initialization time and space complexity is O(1), and the space complexity at any given moment is O of the number of elements in the data structure. Describe how a vector of length m can be represented to support insertion at position i, reading from position i, and deletion at position i in O(\log m) worst-case time for each operation.
\end{quote}","\textbf{Central Data Structure: AVL Tree. Short Description:} The key of an element will be the index \( i \), and the value will be the content of the vector at index \( i \)."
"\textbf{In the following section, the time and space complexity of initialization is \(O(1)\), and the space complexity at any given moment is \(O\) of the number of elements in the data structure. Describe how a matrix of size \(m \times m\) can be represented, supporting the operations of insertion at position \((i,j)\), reading from position \((i,j)\), and deletion from position \((i,j)\), in \(O(\log m)\) worst-case time for each operation.}","\textbf{Central Data Structure:} AVL Tree. \textbf{Brief Description:}
The key will be the pair (i,j) where the comparison between keys will be lexicographic (compare i, and if there is a tie, compare j).
The value will be the content of the matrix at position (i,j)."
Two AVL trees of size \( n \) each are given. Can they be merged in \( O(n) \) time? Prove using an algorithm or disprove.,"\textbf{Proof.} Perform an in-order walk on each of the trees and obtain two sorted arrays of their elements. Perform a merge sort to obtain a single sorted array. Construct a balanced tree from it as follows: the median will be the root, the 1/4 and 3/4 order statistics will be the left and right child of the root respectively, and so on."
"Given two AVL trees of size \( n \) each, is it possible to merge them in \( O(\sqrt{n}) \) time? Prove using an algorithm or a contradiction.","It is not possible. Suppose it were possible, then we could sort \( n \) numbers in less than \( O(n \log n) \) time by recursive merging followed by an in-order walk. The recurrence relation described is \( T(n) = 2T(n/2) + O(n) \), and its solution is \( O(n) \). Therefore, the total sorting time would be \( O(n) \)."
