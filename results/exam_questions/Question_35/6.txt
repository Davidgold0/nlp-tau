Question: Let \( U = \{0, 1, \dots, u\} \). Assume that each element of \( U \) can be represented by a single word. Given a subset \( D \subseteq U \) of size \( n \), describe the most efficient probabilistic algorithm that constructs a function \( h: U \to \{0, 1, \dots, 100n\} \) which is injective on \( D \) (i.e., for all \( x, y \in D \), we have \( h(x) \neq h(y) \)). The memory required to represent the function \( h \) should be \( O(n) \). Computing \( h(x) \), given \( x \in D \), should take \( O(1) \) time in the worst case.
3o-mini: We will describe a minimal‐perfect–hash construction that uses only O(n) space and allows evaluating h(x) in O(1) worst‐case time. (There are several “minimal perfect hashing” schemes in the literature; one popular approach is due to Czech, Havas, and Majewski. Any description equivalent to the following is acceptable.)

Recall that D ⊆ U is an n–element subset of U = {0, 1, . . . , u}. We want to construct a function
  h : U → {0, 1, . . . , 100n}
with the following properties:
 • h is injective on D,
 • h uses only O(n) memory for its description,
 • for any x ∈ D, h(x) can be computed in O(1) worst-case time.

One way to achieve this is by constructing h in two phases. The idea is to “encode” the elements of D via a random graph and then solve for some “offset” values that yield a minimal perfect hash. Here is the step–by–step description:

─────────────────────────────── 
1. Pick Two Random Hash Functions

Choose two “simple” random hash functions
  h1, h2 : U → {0, 1, …, 100n – 1}. 
These functions may be chosen from a 2–universal family (or even a pair of random linear functions modulo a prime larger than u). Since every element of U fits in one word, these functions can be computed in O(1) time.

─────────────────────────────── 
2. Construct a Graph

Now form an undirected graph G = (V, E) where:
  • The vertex set is V = {0, 1, …, 100n – 1}.
  • For each element x ∈ D, add an edge between vertices h1(x) and h2(x); that is,
    E = { (h1(x), h2(x)) : x ∈ D }.

Note that G has exactly n edges (one per element of D). It can be shown that if the range size (here 100n) is a sufficiently large constant multiple of n, then with high probability (over the random choice of h1 and h2) the graph will be acyclic.

─────────────────────────────── 
3. Check for Acyclicity and Reselect if Necessary

Test whether G is acyclic. (Because G has O(n) vertices and n edges, an acyclicity check can be done in O(n) time.)
  • If G is not acyclic, then discard h1 and h2 and go back to step 1.
  • Otherwise, continue with the acyclic graph G.

─────────────────────────────── 
4. Compute “Offset” Values by Traversal

With an acyclic graph G you can assign an integer value g(v) to each vertex v ∈ V such that for every x ∈ D the following holds:
  g( h1(x) ) + g( h2(x) ) ≡ f(x) (mod 100n)
for a suitable scheme f that will soon “label” x uniquely. One convenient choice is simply to set
  h(x) = ( g( h1(x) ) + g( h2(x) ) ) mod (100n)
and then use the fact that if you assign the g(v)’s properly (by, say, traversing G in a depth–first search order), then h will be injective on D. (Intuitively, if there is no cycle, then there is a unique solution for the “offsets” that “explains” the values on every edge uniquely.)

A standard way to do this is as follows:
  a. For each connected component of G, pick an arbitrary root vertex.
  b. Do a depth–first traversal of the component.
  c. For every edge corresponding to an element x ∈ D that goes from a vertex v to a “child” vertex w, set:
    g(w) = [ f(x) – g(v) ] mod (100n)
where f(x) may be chosen to be a unique “temporary label” for x (for instance, set f(x) = the index of x in some ordering of D, say, in 0..n–1). (There is a little freedom in how exactly these equations are set up; the important part is that they force h(x) = g(h1(x)) + g(h2(x)) mod (100n) to be unique on D.)
  d. Once you have assigned all g(v) values, you have completely defined h.

Since G is acyclic and each vertex is visited only once, this phase takes O(n) time and the total space needed for storing all the g(v) values is O(n).

─────────────────────────────── 
5. Evaluating h

Now, for any x ∈ D (and for any x ∈ U if desired), h is quickly computed as:
  h(x) = ( g( h1(x) ) + g( h2(x) ) ) mod (100n)
Since h1 and h2 are O(1) functions and the table g is of size O(n), the evaluation takes O(1) worst–case time.

─────────────────────────────── 
6. Correctness and Efficiency

By the construction, the graph being acyclic ensures that the system of “offset” assignments has a unique solution and that the overall function h is injective on D. The probability that two random hash functions h1 and h2 (from a 2–universal family) produce a cyclic graph is low when the number of vertices (100n) is a fixed constant times n (in this case 100). Therefore, the expected running time of the construction is O(n). The space required is O(n) for storing the g table (and the description of the hash functions h1 and h2, which is also O(n) or less).

─────────────────────────────── 
Summary

A high–level description of the probabilistic algorithm is:

 1. Choose two independent random hash functions h1, h2 : U → {0, 1, …, 100n – 1}.
 2. Build the graph G = (V, E) with V = {0, 1, …, 100n – 1} and edges E = { (h1(x), h2(x)) : x ∈ D }.
 3. If G is cyclic, go back to (1); else, for each connected component of G, compute an assignment g : V → {0, 1, …} by a depth-first search so that for every x ∈ D, the final function h defined by
   h(x) = ( g( h1(x) ) + g( h2(x) ) ) mod (100n)
is injective on D.
 4. The memory used is O(n), and for any x ∈ D the value h(x) is computed in O(1) worst-case time.

This is one of the most efficient (both in time and space) probabilistic constructions for minimal perfect hashing.

Any answer that outlines a similar two-level (or graph–based) construction with O(n) memory and O(1) evaluation time is correct.