Question: Given \( n \) segments on a line (each segment is defined by its start and end points). For simplicity, assume that all \( 2n \) points are distinct. A segment is called "central" if there are at least \( n/4 \) segments that start before it (i.e., their starting point is to the left of its starting point) and there are at least \( n/4 \) segments that end after it (i.e., their ending point is to the right of its ending point). Propose a dynamic data structure that supports the operations Insert and Delete of segments on the line in \( O(\log n) \) worst-case time, and also supports the operation IsCentric(p), which takes a pointer to a segment in the structure and answers whether the segment is central, in \( O(1) \) worst-case time.
3o-mini: We will show that the following idea works. Recall that a segment s is “central” if

 (1) at least n/4 segments start before s, and 
 (2) at least n/4 segments end after s.

Since all endpoints are distinct, if we sort the segments by their starting point then “at least n/4 segments start before s” is equivalent to saying that s has rank (in this sorted order) at least n/4+1. (For example, if s is the (n/4+1)st segment then exactly n/4 segments start before it.) Similarly, if we sort the segments by their ending point, then s is “central” if its ending point is not too far to the right—in precise terms, its rank (in the order by ending point) is at most 3n/4 (since at least n/4 segments must come after it). (You may also view this as “at least n/4 segments end after s,” which is equivalent to s having the (n/4+1)st largest endpoint if you reverse the order.) 

The key observation is that if we can quickly tell the “threshold” values for starting and ending points, then given any segment s (with a pointer into our structure) we can determine in O(1) time whether s meets these criteria.

The Data Structure

We build the following data structure:

1. Two balanced binary search trees (BBST’s) augmented with subtree sizes (that is, order‐statistic trees).  
  a. Tree A: Stores all segments keyed by their starting point.  
  b. Tree B: Stores all segments keyed by their ending point.

2. In addition, we also keep two global pointers (or simply store two pieces of extra information that can be accessed in O(1) time):
  – S_thr: The segment which is the (⌊n/4⌋+1)st smallest by starting point (i.e. its starting point is “just to the right” of the first n/4 segments).
  – E_thr: The segment which is the (⌊n/4⌋+1)st largest by ending point (or equivalently, the segment with rank n–⌊n/4⌋ among all segments sorted in increasing order by ending point).

Notice that the exact value n/4 might need to be replaced by ⌊n/4⌋ (or ⌈n/4⌉) depending on how you want to break ties when n is not a multiple of 4; the details can be worked out using standard methods.

Operations

Insert(segment s):

 • Insert s into Tree A (using its starting point as key). This takes O(log n) worst-case time.
 • Insert s into Tree B (using its ending point as key). This also takes O(log n).
 • Since the total number of segments n changes, update S_thr and E_thr by performing a “select” query on the respective trees.
  – In an order statistic tree, selecting the kth element takes O(log n) worst-case time.
 • Thus, the overall Insert takes O(log n) worst-case time.

Delete(segment s):

 • Delete s from Tree A and Tree B (each in O(log n) worst-case time).
 • Update the globals S_thr and E_thr via select queries to account for the new n.
 • Overall time: O(log n).

IsCentric(pointer p):

Given a pointer p to a segment in our data structure, we can now answer whether p is central in O(1) time as follows.

 • Let s = the segment pointed to by p.
 • Compare s’s starting point with S_thr’s starting point.
  – s is “good” with respect to starting points if s.start ≥ S_thr.start. (That is, s is at position ⌊n/4⌋+1 or later.)
 • Similarly, compare s’s ending point with E_thr’s ending point.
  – s is “good” with respect to ending points if s.end ≤ E_thr.end.
 • Then s is central if and only if both conditions hold.
 • Since each comparison takes O(1) time, IsCentric(p) takes O(1) worst-case time.

Conclusion

With the above structure we have achieved:

 – Insert: O(log n) worst-case time,
 – Delete: O(log n) worst-case time,
 – IsCentric: O(1) worst-case time.

This data structure works because the “global” thresholds S_thr and E_thr let us check the centrality condition in constant time, while the order statistic trees allow us to update these thresholds efficiently on every insertion and deletion.

This solution meets the problem requirements.